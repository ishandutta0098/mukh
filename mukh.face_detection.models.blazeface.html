

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mukh.face_detection.models.blazeface package &mdash; mukh 0.0.37 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=e59714d7" />

  
      <script src="_static/jquery.js?v=5d32c60e"></script>
      <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="_static/documentation_options.js?v=aa2ad26f"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            mukh
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="modules.html">mukh</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">mukh</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">mukh.face_detection.models.blazeface package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/mukh.face_detection.models.blazeface.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="mukh-face-detection-models-blazeface-package">
<h1>mukh.face_detection.models.blazeface package<a class="headerlink" href="#mukh-face-detection-models-blazeface-package" title="Link to this heading"></a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Link to this heading"></a></h2>
</section>
<section id="module-mukh.face_detection.models.blazeface.blazeface_detector">
<span id="mukh-face-detection-models-blazeface-blazeface-detector-module"></span><h2>mukh.face_detection.models.blazeface.blazeface_detector module<a class="headerlink" href="#module-mukh.face_detection.models.blazeface.blazeface_detector" title="Link to this heading"></a></h2>
<p>BlazeFace face detection model implementation.</p>
<p>This module implements the BlazeFace face detection model from MediaPipe.
Adapted from: <a class="reference external" href="https://github.com/hollance/BlazeFace-PyTorch">https://github.com/hollance/BlazeFace-PyTorch</a>
Original implementation by M.I. Hollemans.</p>
<p>The model is optimized for mobile devices and provides both bounding box
detection and 6 facial landmarks.</p>
<dl class="py class">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.blazeface_detector.BlazeFaceDetector">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mukh.face_detection.models.blazeface.blazeface_detector.</span></span><span class="sig-name descname"><span class="pre">BlazeFaceDetector</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">weights_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">anchors_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">confidence_threshold</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.75</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'cpu'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mukh/face_detection/models/blazeface/blazeface_detector.html#BlazeFaceDetector"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mukh.face_detection.models.blazeface.blazeface_detector.BlazeFaceDetector" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="mukh.face_detection.models.html#mukh.face_detection.models.base_detector.BaseFaceDetector" title="mukh.face_detection.models.base_detector.BaseFaceDetector"><code class="xref py py-class docutils literal notranslate"><span class="pre">BaseFaceDetector</span></code></a></p>
<p>BlazeFace face detector implementation.</p>
<p>A lightweight face detector that provides both bounding boxes and facial
landmarks. Optimized for mobile devices.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.blazeface_detector.BlazeFaceDetector.device">
<span class="sig-name descname"><span class="pre">device</span></span><a class="headerlink" href="#mukh.face_detection.models.blazeface.blazeface_detector.BlazeFaceDetector.device" title="Link to this definition"></a></dt>
<dd><p>PyTorch device (CPU/CUDA) for model execution</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.blazeface_detector.BlazeFaceDetector.net">
<span class="sig-name descname"><span class="pre">net</span></span><a class="headerlink" href="#mukh.face_detection.models.blazeface.blazeface_detector.BlazeFaceDetector.net" title="Link to this definition"></a></dt>
<dd><p>BlazeFace neural network model</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.blazeface_detector.BlazeFaceDetector.confidence_threshold">
<span class="sig-name descname"><span class="pre">confidence_threshold</span></span><a class="headerlink" href="#mukh.face_detection.models.blazeface.blazeface_detector.BlazeFaceDetector.confidence_threshold" title="Link to this definition"></a></dt>
<dd><p>Minimum confidence for valid detections</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.blazeface_detector.BlazeFaceDetector.detect">
<span class="sig-name descname"><span class="pre">detect</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_csv</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">csv_path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'detections.csv'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_annotated</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_folder</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'output'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="mukh.core.html#mukh.core.types.FaceDetection" title="mukh.core.types.FaceDetection"><span class="pre">FaceDetection</span></a><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/mukh/face_detection/models/blazeface/blazeface_detector.html#BlazeFaceDetector.detect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mukh.face_detection.models.blazeface.blazeface_detector.BlazeFaceDetector.detect" title="Link to this definition"></a></dt>
<dd><p>Detects faces in the given image.</p>
<p>The image is resized to 128x128 pixels for inference and the results
are scaled back to the original image size.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image_path</strong> – Path to the input image.</p></li>
<li><p><strong>save_csv</strong> – Whether to save detection results to CSV file.</p></li>
<li><p><strong>csv_path</strong> – Path where to save the CSV file.</p></li>
<li><p><strong>save_annotated</strong> – Whether to save annotated image with bounding boxes.</p></li>
<li><p><strong>output_folder</strong> – Folder path where to save annotated images.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><dl class="simple">
<dt>List of detected faces, each containing:</dt><dd><ul class="simple">
<li><p>bbox: BoundingBox with coordinates and confidence</p></li>
<li><p>landmarks: Array of 6 facial keypoints</p></li>
</ul>
</dd>
</dl>
</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>List[<a class="reference internal" href="mukh.core.html#mukh.core.types.FaceDetection" title="mukh.core.types.FaceDetection">FaceDetection</a>]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-mukh.face_detection.models.blazeface.blazeface_torch">
<span id="mukh-face-detection-models-blazeface-blazeface-torch-module"></span><h2>mukh.face_detection.models.blazeface.blazeface_torch module<a class="headerlink" href="#module-mukh.face_detection.models.blazeface.blazeface_torch" title="Link to this heading"></a></h2>
<p>BlazeFace PyTorch implementation adapted from:
<a class="reference external" href="https://github.com/hollance/BlazeFace-PyTorch">https://github.com/hollance/BlazeFace-PyTorch</a></p>
<p>Original implementation by M.I. Hollemans</p>
<dl class="py class">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.blazeface_torch.BlazeBlock">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mukh.face_detection.models.blazeface.blazeface_torch.</span></span><span class="sig-name descname"><span class="pre">BlazeBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mukh/face_detection/models/blazeface/blazeface_torch.html#BlazeBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mukh.face_detection.models.blazeface.blazeface_torch.BlazeBlock" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.blazeface_torch.BlazeBlock.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mukh/face_detection/models/blazeface/blazeface_torch.html#BlazeBlock.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mukh.face_detection.models.blazeface.blazeface_torch.BlazeBlock.forward" title="Link to this definition"></a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.blazeface_torch.BlazeFace">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mukh.face_detection.models.blazeface.blazeface_torch.</span></span><span class="sig-name descname"><span class="pre">BlazeFace</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">back_model</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mukh/face_detection/models/blazeface/blazeface_torch.html#BlazeFace"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mukh.face_detection.models.blazeface.blazeface_torch.BlazeFace" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>The BlazeFace face detection model from MediaPipe.</p>
<p>The version from MediaPipe is simpler than the one in the paper;
it does not use the “double” BlazeBlocks.</p>
<p>Because we won’t be training this model, it doesn’t need to have
batchnorm layers. These have already been “folded” into the conv
weights by TFLite.</p>
<p>The conversion to PyTorch is fairly straightforward, but there are
some small differences between TFLite and PyTorch in how they handle
padding on conv layers with stride 2.</p>
<p>This version works on batches, while the MediaPipe version can only
handle a single image at a time.</p>
<p>Based on code from <a class="reference external" href="https://github.com/tkat0/PyTorch_BlazeFace/">https://github.com/tkat0/PyTorch_BlazeFace/</a> and
<a class="reference external" href="https://github.com/google/mediapipe/">https://github.com/google/mediapipe/</a></p>
<dl class="py method">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.blazeface_torch.BlazeFace.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mukh/face_detection/models/blazeface/blazeface_torch.html#BlazeFace.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mukh.face_detection.models.blazeface.blazeface_torch.BlazeFace.forward" title="Link to this definition"></a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.blazeface_torch.BlazeFace.load_anchors">
<span class="sig-name descname"><span class="pre">load_anchors</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mukh/face_detection/models/blazeface/blazeface_torch.html#BlazeFace.load_anchors"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mukh.face_detection.models.blazeface.blazeface_torch.BlazeFace.load_anchors" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.blazeface_torch.BlazeFace.load_weights">
<span class="sig-name descname"><span class="pre">load_weights</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mukh/face_detection/models/blazeface/blazeface_torch.html#BlazeFace.load_weights"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mukh.face_detection.models.blazeface.blazeface_torch.BlazeFace.load_weights" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.blazeface_torch.BlazeFace.predict_on_batch">
<span class="sig-name descname"><span class="pre">predict_on_batch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mukh/face_detection/models/blazeface/blazeface_torch.html#BlazeFace.predict_on_batch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mukh.face_detection.models.blazeface.blazeface_torch.BlazeFace.predict_on_batch" title="Link to this definition"></a></dt>
<dd><p>Makes a prediction on a batch of images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> – a NumPy array of shape (b, H, W, 3) or a PyTorch tensor of
shape (b, 3, H, W). The height and width should be 128 pixels.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list containing a tensor of face detections for each image in
the batch. If no faces are found for an image, returns a tensor
of shape (0, 17).</p>
</dd>
</dl>
<dl class="simple">
<dt>Each face detection is a PyTorch tensor consisting of 17 numbers:</dt><dd><ul class="simple">
<li><p>ymin, xmin, ymax, xmax</p></li>
<li><p>x,y-coordinates for the 6 keypoints</p></li>
<li><p>confidence score</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.blazeface_torch.BlazeFace.predict_on_image">
<span class="sig-name descname"><span class="pre">predict_on_image</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">img</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mukh/face_detection/models/blazeface/blazeface_torch.html#BlazeFace.predict_on_image"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mukh.face_detection.models.blazeface.blazeface_torch.BlazeFace.predict_on_image" title="Link to this definition"></a></dt>
<dd><p>Makes a prediction on a single image.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>img</strong> – a NumPy array of shape (H, W, 3) or a PyTorch tensor of
shape (3, H, W). The image’s height and width should be
128 pixels.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor with face detections.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.blazeface_torch.FinalBlazeBlock">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mukh.face_detection.models.blazeface.blazeface_torch.</span></span><span class="sig-name descname"><span class="pre">FinalBlazeBlock</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">3</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mukh/face_detection/models/blazeface/blazeface_torch.html#FinalBlazeBlock"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mukh.face_detection.models.blazeface.blazeface_torch.FinalBlazeBlock" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.blazeface_torch.FinalBlazeBlock.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mukh/face_detection/models/blazeface/blazeface_torch.html#FinalBlazeBlock.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mukh.face_detection.models.blazeface.blazeface_torch.FinalBlazeBlock.forward" title="Link to this definition"></a></dt>
<dd><p>Define the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.blazeface_torch.intersect">
<span class="sig-prename descclassname"><span class="pre">mukh.face_detection.models.blazeface.blazeface_torch.</span></span><span class="sig-name descname"><span class="pre">intersect</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">box_a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">box_b</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mukh/face_detection/models/blazeface/blazeface_torch.html#intersect"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mukh.face_detection.models.blazeface.blazeface_torch.intersect" title="Link to this definition"></a></dt>
<dd><p>We resize both tensors to [A,B,2] without new malloc:
[A,2] -&gt; [A,1,2] -&gt; [A,B,2]
[B,2] -&gt; [1,B,2] -&gt; [A,B,2]
Then we compute the area of intersect between box_a and box_b.
:param box_a: (tensor) bounding boxes, Shape: [A,4].
:param box_b: (tensor) bounding boxes, Shape: [B,4].</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>[A,B].</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>(tensor) intersection area, Shape</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.blazeface_torch.jaccard">
<span class="sig-prename descclassname"><span class="pre">mukh.face_detection.models.blazeface.blazeface_torch.</span></span><span class="sig-name descname"><span class="pre">jaccard</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">box_a</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">box_b</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mukh/face_detection/models/blazeface/blazeface_torch.html#jaccard"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mukh.face_detection.models.blazeface.blazeface_torch.jaccard" title="Link to this definition"></a></dt>
<dd><p>Compute the jaccard overlap of two sets of boxes.  The jaccard overlap
is simply the intersection over union of two boxes.  Here we operate on
ground truth boxes and default boxes.
E.g.:</p>
<blockquote>
<div><p>A ∩ B / A ∪ B = A ∩ B / (area(A) + area(B) - A ∩ B)</p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>box_a</strong> – (tensor) Ground truth bounding boxes, Shape: [num_objects,4]</p></li>
<li><p><strong>box_b</strong> – (tensor) Prior boxes from priorbox layers, Shape: [num_priors,4]</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>(tensor) Shape: [box_a.size(0), box_b.size(0)]</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>jaccard overlap</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.blazeface_torch.overlap_similarity">
<span class="sig-prename descclassname"><span class="pre">mukh.face_detection.models.blazeface.blazeface_torch.</span></span><span class="sig-name descname"><span class="pre">overlap_similarity</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">box</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">other_boxes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mukh/face_detection/models/blazeface/blazeface_torch.html#overlap_similarity"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mukh.face_detection.models.blazeface.blazeface_torch.overlap_similarity" title="Link to this definition"></a></dt>
<dd><p>Computes the IOU between a bounding box and set of other boxes.</p>
</dd></dl>

</section>
<section id="module-mukh.face_detection.models.blazeface.face_extract">
<span id="mukh-face-detection-models-blazeface-face-extract-module"></span><h2>mukh.face_detection.models.blazeface.face_extract module<a class="headerlink" href="#module-mukh.face_detection.models.blazeface.face_extract" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.face_extract.FaceExtractor">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mukh.face_detection.models.blazeface.face_extract.</span></span><span class="sig-name descname"><span class="pre">FaceExtractor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">video_read_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">facedet</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="mukh.deepfake_detection.models.efficientnet.blazeface.html#mukh.deepfake_detection.models.efficientnet.blazeface.blazeface.BlazeFace" title="mukh.deepfake_detection.models.efficientnet.blazeface.blazeface.BlazeFace"><span class="pre">BlazeFace</span></a></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mukh/face_detection/models/blazeface/face_extract.html#FaceExtractor"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mukh.face_detection.models.blazeface.face_extract.FaceExtractor" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Wrapper for face extraction workflow.</p>
<dl class="py method">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.face_extract.FaceExtractor.get_tiles_params">
<span class="sig-name descname"><span class="pre">get_tiles_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">H</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">W</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mukh/face_detection/models/blazeface/face_extract.html#FaceExtractor.get_tiles_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mukh.face_detection.models.blazeface.face_extract.FaceExtractor.get_tiles_params" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.face_extract.FaceExtractor.keep_only_best_face">
<span class="sig-name descname"><span class="pre">keep_only_best_face</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">crops</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mukh/face_detection/models/blazeface/face_extract.html#FaceExtractor.keep_only_best_face"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mukh.face_detection.models.blazeface.face_extract.FaceExtractor.keep_only_best_face" title="Link to this definition"></a></dt>
<dd><p>For each frame, only keeps the face with the highest confidence.</p>
<p>This gets rid of false positives, but obviously is problematic for
videos with two people!</p>
<p>This is an optional postprocessing step. Modifies the original
data structure.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.face_extract.FaceExtractor.process_image">
<span class="sig-name descname"><span class="pre">process_image</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">img</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Image</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">dict</span></span></span><a class="reference internal" href="_modules/mukh/face_detection/models/blazeface/face_extract.html#FaceExtractor.process_image"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mukh.face_detection.models.blazeface.face_extract.FaceExtractor.process_image" title="Link to this definition"></a></dt>
<dd><p>Process a single image
:param path: Path to the image
:param img: image
:return:</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.face_extract.FaceExtractor.process_video">
<span class="sig-name descname"><span class="pre">process_video</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">video_path</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mukh/face_detection/models/blazeface/face_extract.html#FaceExtractor.process_video"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mukh.face_detection.models.blazeface.face_extract.FaceExtractor.process_video" title="Link to this definition"></a></dt>
<dd><p>Convenience method for doing face extraction on a single video.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.face_extract.FaceExtractor.process_videos">
<span class="sig-name descname"><span class="pre">process_videos</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filenames</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">video_idxs</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">dict</span><span class="p"><span class="pre">]</span></span></span></span><a class="reference internal" href="_modules/mukh/face_detection/models/blazeface/face_extract.html#FaceExtractor.process_videos"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mukh.face_detection.models.blazeface.face_extract.FaceExtractor.process_videos" title="Link to this definition"></a></dt>
<dd><p>For the specified selection of videos, grabs one or more frames
from each video, runs the face detector, and tries to find the faces
in each frame.</p>
<p>The frames are split into tiles, and the tiles from the different videos
are concatenated into a single batch. This means the face detector gets
a batch of size len(video_idxs) * num_frames * num_tiles (usually 3).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_dir</strong> – base folder where the video files are stored</p></li>
<li><p><strong>filenames</strong> – list of all video files in the input_dir</p></li>
<li><p><strong>video_idxs</strong> – one or more indices from the filenames list; these
are the videos we’ll actually process</p></li>
</ul>
</dd>
</dl>
<p>Returns a list of dictionaries, one for each frame read from each video.</p>
<dl class="simple">
<dt>This dictionary contains:</dt><dd><ul class="simple">
<li><p>video_idx: the video this frame was taken from</p></li>
<li><p>frame_idx: the index of the frame in the video</p></li>
<li><p>frame_w, frame_h: original dimensions of the frame</p></li>
<li><p>faces: a list containing zero or more NumPy arrays with a face crop</p></li>
<li><p>scores: a list array with the confidence score for each face crop</p></li>
</ul>
</dd>
</dl>
<p>If reading a video failed for some reason, it will not appear in the
output array. Note that there’s no guarantee a given video will actually
have num_frames results (as soon as a reading problem is encountered for
a video, we continue with the next video).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.face_extract.FaceExtractor.remove_large_crops">
<span class="sig-name descname"><span class="pre">remove_large_crops</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">crops</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">pct</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mukh/face_detection/models/blazeface/face_extract.html#FaceExtractor.remove_large_crops"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mukh.face_detection.models.blazeface.face_extract.FaceExtractor.remove_large_crops" title="Link to this definition"></a></dt>
<dd><p>Removes faces from the results if they take up more than X%
of the video. Such a face is likely a false positive.</p>
<p>This is an optional postprocessing step. Modifies the original
data structure.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>crops</strong> – a list of dictionaries with face crop data</p></li>
<li><p><strong>pct</strong> – maximum portion of the frame a crop may take up</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-mukh.face_detection.models.blazeface.read_video">
<span id="mukh-face-detection-models-blazeface-read-video-module"></span><h2>mukh.face_detection.models.blazeface.read_video module<a class="headerlink" href="#module-mukh.face_detection.models.blazeface.read_video" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.read_video.VideoReader">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mukh.face_detection.models.blazeface.read_video.</span></span><span class="sig-name descname"><span class="pre">VideoReader</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">insets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0,</span> <span class="pre">0)</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mukh/face_detection/models/blazeface/read_video.html#VideoReader"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mukh.face_detection.models.blazeface.read_video.VideoReader" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Helper class for reading one or more frames from a video file.</p>
<dl class="py method">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.read_video.VideoReader.read_frame_at_index">
<span class="sig-name descname"><span class="pre">read_frame_at_index</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frame_idx</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mukh/face_detection/models/blazeface/read_video.html#VideoReader.read_frame_at_index"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mukh.face_detection.models.blazeface.read_video.VideoReader.read_frame_at_index" title="Link to this definition"></a></dt>
<dd><p>Reads a single frame from a video.</p>
<p>If you just want to read a single frame from the video, this is more
efficient than scanning through the video to find the frame. However,
for reading multiple frames it’s not efficient.</p>
<p>My guess is that a “streaming” approach is more efficient than a
“random access” approach because, unless you happen to grab a keyframe,
the decoder still needs to read all the previous frames in order to
reconstruct the one you’re asking for.</p>
<p>Returns a NumPy array of shape (1, H, W, 3) and the index of the frame,
or None if reading failed.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.read_video.VideoReader.read_frames">
<span class="sig-name descname"><span class="pre">read_frames</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_frames</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">jitter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mukh/face_detection/models/blazeface/read_video.html#VideoReader.read_frames"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mukh.face_detection.models.blazeface.read_video.VideoReader.read_frames" title="Link to this definition"></a></dt>
<dd><p>Reads frames that are always evenly spaced throughout the video.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> – the video file</p></li>
<li><p><strong>num_frames</strong> – how many frames to read, -1 means the entire video
(warning: this will take up a lot of memory!)</p></li>
<li><p><strong>jitter</strong> – if not 0, adds small random offsets to the frame indices;
this is useful so we don’t always land on even or odd frames</p></li>
<li><p><strong>seed</strong> – random seed for jittering; if you set this to a fixed value,
you probably want to set it only on the first video</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.read_video.VideoReader.read_frames_at_indices">
<span class="sig-name descname"><span class="pre">read_frames_at_indices</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">frame_idxs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mukh/face_detection/models/blazeface/read_video.html#VideoReader.read_frames_at_indices"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mukh.face_detection.models.blazeface.read_video.VideoReader.read_frames_at_indices" title="Link to this definition"></a></dt>
<dd><p>Reads frames from a video and puts them into a NumPy array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> – the video file</p></li>
<li><p><strong>frame_idxs</strong> – a list of frame indices. Important: should be
sorted from low-to-high! If an index appears multiple
times, the frame is still read only once.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p>a NumPy array of shape (num_frames, height, width, 3)</p></li>
<li><p>a list of the frame indices that were read</p></li>
</ul>
</p>
</dd>
</dl>
<p>Reading stops if loading a frame fails, in which case the first
dimension returned may actually be less than num_frames.</p>
<p>Returns None if an exception is thrown for any reason, or if no
frames were read.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.read_video.VideoReader.read_middle_frame">
<span class="sig-name descname"><span class="pre">read_middle_frame</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mukh/face_detection/models/blazeface/read_video.html#VideoReader.read_middle_frame"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mukh.face_detection.models.blazeface.read_video.VideoReader.read_middle_frame" title="Link to this definition"></a></dt>
<dd><p>Reads the frame from the middle of the video.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.read_video.VideoReader.read_random_frames">
<span class="sig-name descname"><span class="pre">read_random_frames</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_frames</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mukh/face_detection/models/blazeface/read_video.html#VideoReader.read_random_frames"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mukh.face_detection.models.blazeface.read_video.VideoReader.read_random_frames" title="Link to this definition"></a></dt>
<dd><p>Picks the frame indices at random.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> – the video file</p></li>
<li><p><strong>num_frames</strong> – how many frames to read, -1 means the entire video
(warning: this will take up a lot of memory!)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.read_video.VideoReaderIspl">
<em class="property"><span class="k"><span class="pre">class</span></span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">mukh.face_detection.models.blazeface.read_video.</span></span><span class="sig-name descname"><span class="pre">VideoReaderIspl</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">insets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">(0,</span> <span class="pre">0)</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mukh/face_detection/models/blazeface/read_video.html#VideoReaderIspl"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mukh.face_detection.models.blazeface.read_video.VideoReaderIspl" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#mukh.face_detection.models.blazeface.read_video.VideoReader" title="mukh.face_detection.models.blazeface.read_video.VideoReader"><code class="xref py py-class docutils literal notranslate"><span class="pre">VideoReader</span></code></a></p>
<p>Derived VideoReader class with overriden read_frames method</p>
<dl class="py method">
<dt class="sig sig-object py" id="mukh.face_detection.models.blazeface.read_video.VideoReaderIspl.read_frames_with_hop">
<span class="sig-name descname"><span class="pre">read_frames_with_hop</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_frames</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fps</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">-1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/mukh/face_detection/models/blazeface/read_video.html#VideoReaderIspl.read_frames_with_hop"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#mukh.face_detection.models.blazeface.read_video.VideoReaderIspl.read_frames_with_hop" title="Link to this definition"></a></dt>
<dd><p>Reads frames up to a certain number spaced throughout the video with a rate decided by the user.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>path</strong> – the video file</p></li>
<li><p><strong>num_frames</strong> – how many frames to read, -1 means the entire video
(warning: this will take up a lot of memory!)</p></li>
<li><p><strong>fps</strong> – how many frames per second to pick</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-mukh.face_detection.models.blazeface">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-mukh.face_detection.models.blazeface" title="Link to this heading"></a></h2>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Ishan Dutta.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>